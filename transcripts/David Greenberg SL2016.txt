   David Greenberg
   StrangeLoop 2016
   Live captioning by Norma Miller @whitecoatcapxg.
   
   >> All right, well, welcome, everyone. Today we're going to be talking about exotic functional data structures and specifically we're going to be talking about hitchhiker trees, my name is David Greenberg, I'm an author. There's this book I wrote on engineering, and now I mostly consult on distributed systems problems and also a little announcement: At 12:30 today I'll be signing and giving away copies of this book. 
   So let's get started here. There's a lot to cover here because functional data structures are pretty complicated. 
   So what are functional data structures? Well, at their core, a functional data core is immutable. That's really the difference between a functional data structure and a regular data structure. So what do immutable mean? When well, consider 7, when we add 1 to 7, we get 8, but the thing is 7 is still 7. In most languages when you add an element to that, that's not what happens. 
   So let's look at some examples in Python just to build some intuition about what a functional data structure actually is. So here we have a Python function where we have X and then we say Y is equal to X. Now, this program prints "I'm a sad panda."  Why is that? It's because when we added the element to Y, we also kind of added it to X by mistake. This is how it goes without functional data structures.
   How do we fix this? Well, I made a little change to the program. If it's not jumping out to, I'll highlight it here, and what this change is this little it actually copies the list X so now we're not saying that X is equal to X, we're saying that Y is a copy of Y.
   So now when we compare these two lists, we see that they are different and so we can be a happy panda. And so that's great, right? This basic idea of copying it turns out it's going to be really important. So here's a list of fruit. Maybe these are my favorite fruit. They're not actually, because I don't really like apples that much so how would I mutate this list to say that I don't like apples, I like mangoes instead.
   So we just copy the list which is in red and we're going to make a new one that's in green. So whenever I give this talk I'm going to highlight, so anything in black hasn't changed, anything in red has been deallocated, and anything in green has been allocated or mutated, just to get a feeling of where we're spending our costs of allocations and deallocations so when we copied this list it's in the process of copying is when we actually made the change. So the old list in red, that's still the exact act same list as before. Kind of like how 7 doesn't change when you add 1 to it, you just get another thing called 8. That's what's going on here.
   Now, this isn't super-great, though, because we did have to copy the entire list. So in order to do it better we are going to have to introduce in new concept. Which is pointers. Now, most languages use these, and you're probably familiar with them but maybe you haven't encountered them. So let's talk about this. This is a struct. It has my name in the first field, it has my occupation, my hair color, my eye color and the thing that I want to point out that is that my name is the first field that's an embedded struct. 
   So inside of this record with four fields inside is a different record with two fields but we've embedded them together. So this is one way to represent data but we can also represent it with a pointer. So we can take that name with the first name and the last time and we can move that off to a different place in the memory and instead of storing the full name embedded in my biometric struct, I can just point it with that arrow. So the one thing that's always going to be in common is there's always going to be angle brackets around them to help you distinguish between actual values and pointers.
   OK, so what's the point of pointers? Well, points enable sharing, so what we can do is if we have something else, say an employee record on the bottom left, we can have a biometrics record and an employee record they can share the same record, so this sharing is really kind of an interesting thing, so let's explore how is pointers which enable sharing, how can that actually help us? So if we go back to our example where we had our struct where we wanted to modify it, make an entirely new copy which forced us to make a new allocation and deallocate the entire array. 
   How can we do better? So we're going to do better by using a linked list. This is a functional singly linked list. So suppose I want to mutate this linked list, right, I want to change that so that instead of having an apple in the front, we want to have a hango in the front. 
   So what we do is just this. And what we've done is we have by because the last four elements are the same, for the old linked list and the new linked list, we only had to allocate and deallocate the first element, right? 
   So this actually saves us a lot of computational resources, a lot of memory allocation and deallocation, because we only had to now allocate and deallocate one element instead of five. So this is better, OK?
   Now, the problem is that in the worst case, this actually gets pretty bad. In fact, it gets linear in the number of elements in the list. So in this case instead I want to say that you know -- I actually changed my mind, I like apples but I'm not a big fan of bananas, so we're going to say -- OK, so now there's something weird going on here, but maybe you're wondering why 3? 
   Because the first two elements are the same? And so this is actually it's a philosophical thing, but it's practical, as well, and so the question is: When is an apple not an apple? In this case I'm referring to the apple at the head of each list. 
   Well, an apple that points to an orange that points to a banana is different than an apple that points to an orange that points to a mango. Yeah, so what does that mean? Well, when we think about pointers, right, remember, pointers are just kind of a different way of representing embedded information into a struct, but instead we're just pointing to it so it can be shared. But really that apple and orange at the beginning of the list, those are different apples and oranges because when we trace down their descendens, their descendent are different. This is an important question that we're going to revisit continuously throughout this talk.
   We are copying the path and we're tracing it all the way back to the root of the data structure. The root is something which nothing points at it and that's what makes it the root. So we have to copy the entire path to the root. In this case copying the entire path could be the whole list and so we've got to do better. We're going to talk about a bunch of different kind of trees, we're going to build up to hitchhiker trees so we're going to talk about binary search trees and then B trees and B+ trees and fractal trees and then hitchhiker trees. 
   So we'll start with binary search trees. Binary search trees, why are they called this? Binary, because there are two children for each node. They're search trees because they're sorted which enables us to do a search. Now, the sort they do, you look at this and you say, you know, David, that doesn't look really sorted to me. Well, the sort that this tree and all trees are going to use is for any node, all children to the left of it are less, all children are the right of it are greater and so we can see this property is true. So if we want to look up the value 3 in the tree, I've highlighted, whenever I want to just call attention to something, we'll make it orange, OK?
   No more colors. So when we highlight it, we're going to look up 3, right, so we'll say, well, where as 3 and we look at the root. Well, the root is 4 hand we know 3 is less than 4 so we can descend to the less. And now we're say we're on 2, we know 23 is greater than 2, so we can go to the right and lo and behold we find 3.
   I want to give you some intuition about how we're going to come up with these big old run times because as we go into B trees and B+ trees and fractal trees and hitchhiker trees, I think it helps to make sure we're all on the same page about where this log-based event is coming from. 
   So if we count the number of events on each level, is indexed 0, we say there's 2 to the 0 elements in the first level and that's one element and of course that's one element, it's the root. And on the second root which is index 1, there's 2 to the 1 elements and you know there are and on the third level there's 2 to the 7 power elements and so on. In big O analysis we only care about the dominating factor, that is, the term of our equation that is the growing biggest fastest. So in our case what's growing biggest fastest? It's the number of leaves in the tree. And so that's what we're going to do the analysis based on. So let's do a little algebra, I'm sorry, but let's you know let's kind of walk through this and see how this works. So we have L levels in the tree. This is just by definition. We have a tree, we count it, how many levels there are, that's L, OK?
   Now, we know that lookups cost L. Hopefully I convinced you that whenever we look up in a value in a tree we're always going to see that it is L levels deep. Now, the other thing is that only the last level matters. I try to give some intuition into why that's the case, and you know, I think that if you don't believing me and it seems a little bit hand-wavy, it is a little hand wavy and there's definitely lots more rigorous ways to teach you this.
   So if N is the number of elements in the last level, then N is equal to 2 to the L minus 1, because we're just kind of plugging definitions into each other.
   So now we do some algebra, you have you've got to trust me this is ow algebra works. L is the number of levels we have in the tree and L is the cost of doing a lookup in the tree so if L is a cost of the lookup in a tree, then log base 2 of N is the cost of lookup in the tree. Now the other thing that I'm going to point out here because it's going to matter is we used 2 to the L minus 1 because there was two children and that 2 is the same 2 that got copied down to the subscript on that log. So we're going to play with this in a little while.
   So functional updates so I've talked about trees, talked about these binary search trees but I haven't talked about a functional binary search tree. What does it mean to be functional? We're going to take that copy from the linked lists and it turns out path copying works way better with trees. 
   So here is an example where we're what the we're going to do here is we're going to change the node which had three and we're going to change it to 3.14, which is similar pi so we have to deallocate that path from the root to 3 and we're allocating this new path from the root to 3.14. 
   A bunch of nodes are staying black. We don't need to change those nodes, we don't need to touch them because about their perspective, their subtrees have not changed at all. And what's cool about this is the updates are still log base 2 of N. Now, the updates for a functional tree are the same cost as the updates for a mutable tree. asymptotically anyway.
   We could get the same performance that we would get out of a mutable data structure. There's a few other properties of trees that are worth knowing about that we're not going to be talking about. 
   Trees are balanced. One of the things we're going to assume is that our trees are balanced. They're sort of triangular with kind of a flat bottom and sloping slides, they're not leaning heavily to one direction, they're not a line that squiggles off into the bottom right or bottom left distance. How are we going to maintain this? If you're interested in learning about that, there's a book called CLRS. The CLRS book is kind of the canonical book of writing how algorithms work. So if you want to read about tree-balancing, you could read CLRS or you could try Wikipedia.
   In this talk we're only going to be talking about sorted trees because these have been interesting to me and these are kind of what all of these trees we're talking about taking advantage of. There is another way to order the values in a tree. And that way of ordering them is called a trie, which is also pronounced tree. So the same stuff we're going to talk about in most cases apply to tries, and that's the way that languages implement their immutable hash maps is they use tries instead of trees.
   OK, so the next thing I want to talk about is what if we change our cost model? So where did that 2 come from in the log base 2 of N? Well, that two came from the number of children that we had to go to, right, there was two children, it was a binary search tree. 
   Now, the thing that we're trying to optimize in that tree, another way to think about that is what was that cost that we were looking at? That height? Well, at each level we had to do a comparison and actually sort of the cost model that a binary search tree is evaluated under is the comparison cost model. We're trying to count how many times do we have to check whether greater than, less than, or equal to. 
   So what if we change our cost model to I already O? It turns out if we want to read data from a disk we're probably get a megabyte of data at a time. It's actually no more efficient reading one byte versus a thousand bytes if we're reading it off a disk.
   So let's try a new idea. What if we actually increased the number of children per level because comparisons aren't really expensive. We can do a bunch of comparisons inside of every node. Instead let's try to make sure each node carries as much data as possible.
   So here's an image of a B tree and if we look at this B tree, we see, OK, it's a tree, kind of ran out of space because they have this branching factor that's really big and the text gets too small if I try to show more levels. So here what we look is we look at root and we say OK, the root has some values, like 5, 10, 15, and 20 and it turns out that same sorting property is the same as this is it is in the binary search tree. 
   So let's look at that. If we look at the first element is 5, we look at the left left-most leaf we see all of those values are less than 5. In fact, they're from 1 to 4 and if we look at all the other leaves, we see that those are greater. 
   So we've crunched up a few levels of that tree, we've sort of scrunched them up into another node. So these B trees they're optimal for reads. There's a lower bound of log base B of N. And that's way beyond the scope of this talk to prove. So it's really cool, though, that we can control the base of the logarithm. With this binary trees, with B trees, we're log base B of N and so why is that cool? 
   So suppose we had a tree with a thousand elements. In that case we're going to spend about 10 units of time. OK, that's cool, 10 units of time seems reasonable, especially if they're small units. But what if we go with that B tree on the side with five children. When we only have five children we're actually going to nearly double the performance, so we just increase number of children happened now we get a constant factor speedup and again what if we wanted a even bigger B tree, 100 children? Well, now we're 7 times faster than the binary tree. It's coming from the amount of data we have to read from discs and so this B tree is allowing us to read more useful data that we can act on on every single time we do I/O and so this is great, by going wide, we get these big constant speedups for free and this is because of this I/O cost model. Now, these are constant speedups, is anybody would be happy if their program was 100 times faster just for free? 
   Yeah, you know, sure, it doesn't get even faster when you run more data, but I'm not going to say no. So, but B free bookkeeping. Though there is something annoying with implementing betrees, which is the bookkeeping is quite a bit trickier. And we don't are have that easy to express invariant of oh, you know, if it's smaller it goes to the left, if it's bigger it goes to the right. Instead, we have K elements on each level and then we have K plus 1 children and they have this particular property and good luck figuring that out. It can be pretty challenging.
   And so there's this idea that a lot of people had saying well, that's kind of annoying temperament. What if instead of storing data throughout the tree, what if we only stored data at the leaves and we only store index information in the trunk and the root around we'll call those index nodes. The other cool thing is throughout this talk we're only looking at the keys in the tree but you remember, often maps are what we worry about, not sets. 
   And along with those numeric key, there's some value associated with it that's just sitting there and so when we change our tree, sams only need to be sorted in data nodes, because the index nodes are storing those keys and the keys are probably smaller. 
   So this is another performance enhancement that people get. And what is this called? This idea of separating the index and the data nodes? Well, that's a B+ tree. It looks similar to the B tree. It's got children, it's got index nodes, but the difference here is what I've done is said OK, the root doesn't store any data, instead of it's just sort of replicating the largest value from that child up. 
   So you can see that the first element of the root is the largest value from the first child and the second one is 8, and so on, and the last one is + and the reason quite + is that just means this is bigger than anything else. But the really big stuff goes over in this direction.
   And so we create this sort and our lookups are going to look the same so if we want to look up the value 9, we scan across the root until we find the first index element which is going to be greater than, which is 12 and then we go it down a level and then we go down that node and there's 9. 
   For the rest of the talk I'm going to reduce this node by 3 kind of pathologically. When we start talking about fractal trees and hitchhiker trees, they really depend on multiple levels of the trees existing because we're going to get some performance optimizations and performance wins by taking advantage of the fact that there are many levels. 
   So from now on we're going to have these three-level trees, and so here's our three-level B tree. So fractal trees. Now we're getting to the good stuff what you maybe came here to hear about. Fractal trees and hitchhiker trees. What is a fractal tree? The difference between this and a B+ tree, I'm pointing right here, it's this idea that each one of the nodes is going to get a limb buffer attached to it. You can see here this fractal tree has buffers of size 2, so it's a B+ tree with extra buffers added to all the index nodes. So a fractal tree, just to say it again, a fractal trees is a B+ tree but we're putting this buffer, this log, this place we can store data temporarily, we're putting that on every one of the index nodes.
   So in order to understand what this is about, I want to make a little aside. Off of trees, let's go back to something simpler and different because you know what, that log base B of N that was only for sorted lookups, right? And inserting into a tree is not a sorted lookup. So we can do better.
   And how we can do better is by appending to a log. Now appending to a log is a constant time direction. So we always know the next index where we need to insert it before we even do the insertion. There's no bookkeeping. There's just incrementing a number tells us where to insert it so we want to insert our first element at index 0 and because we inserted that element at index 1 we know the next one belongs at index 1 and the next one at index 2 and 3, and the last one at 4. 
   There was no tree balancing. There was no complex algorithm to do this. It was really fast to just append to the log and so when we consider a fractal tree, this is what we're going to take advantage of is that each of these little buffers that we stuck on the index nodes, each of those little logs, those are going to be really fast to insert into and we're going to take advantage of that to smooth out the performance of our B trees insertions.
   So let's start. We insert 0 into this tree and we stuck it right there right in the root node. Because that insertion of 0, there was space for it in the buffer up there.
   And the other thing that I want to point out, I want to highlight here is, is that we only even had to touch the root node. We literally don't care what the rest of the tree is doing or what's going on. This operation costed one. It's only one thing we touched. It's very, very efficient.
   So let's insert another element. -1. And once again it fits in the buffer of the root node. We only have to touch the root node and so this is already better than what a B+ tree would require.
   So now let's insert a new value, 28, so I want you to think for a second, you know we're going to insert 28, what might happen, where are those values going to go? Because we don't have space in that buffer anymore. All right, time's up. 
   So what we're going to do is insert that, we still want to insert that in the root, but what we have to do first is to free up that space and we're free up the space by flushing though values down and so here you can see that those values, when they get flushed, they're going to the left. All right, they're going down to the left level, and the reason for that is if you think about where would we like to insert those if this wasn't a fractal tree? 
   Well, we would insert them all the way on the bottom left of the tree and that's because they're the smallest elements, right? They're even smaller than the current smallest elements of the tree. So they belong in that direction so we're going to flush them down in that direction. 
   And after we turn them down, that frees them and we can do a new insertion. So we'll keep going, we're going to insert 29 and we'll inherit -2, which is also great, we're going to flush 28 and 29 down this time to that side and you know, they fit and we have new space in the root again. 
   We're going to insert 11.5 and now at this point I just want to pause for a second and say at this point something interesting is going to happen on our next insertion, because 11.5 can go to the middle node, right, there's space for it there, but -2 that's going to be going over to the left. And so it doesn't really fit, right, though? Well, when we insert this additional value, what happens is we're going to have to flush, but we're going to flush recursively, right, so actually flushing is actually a recursive operation in ha fractal tree, and so what we ended up doing here was -1 and 0, they got flushed so far down that they became a leaf of the tree. In fact the way the fractal trees are implemented is they are actually going to trigger the standard B+ standard insertion algorithm.
   So this is how these rights work, it's this idea of we have these buffers, we fill up the buffers, when a buffer fills up, we flush it down to the next level recursively until we find enough space and when it hits the bottom that's when we actually insert it into a tree like we normally would. And so this is a fractal tree and it gives us this big improvement in write performance. What about reads, though? It's not so obvious how we're going to read this data because the trees are not really in sorted order anymore.
   Well, let's look at an example of how we can do a read. So here we have a super-simple fractal tree, almost nothing going on it in and we want to look up 20 so to look up a value in a fractal tree, it's actually a two-step process, so the first thing we do is find the path that we want to do that lookup, the same kind of pathfinding that we did for the binary search trees and the B trees and the B+ trees. And then what we do and this is the cool part is we're going to project the pending operations so just to highlight that, we're taking every one of the pending operations that was along that path that we did the lookup on and we're going to project them all down into that leaf node. Essentially it turns out, even for a fractal tree, which is mutable, we still need to use functional data structures for this part of the operation, because we want to make sure, we're not actually changing the tree, but in order to do the lookup, we have to pretend like we're changing the tree. So it's kind of like we have our old node value which hasn't changed over here, but we have to create the simulated new value.
   So once we do this simulation of the new leaf, now we can actually look up directly on the leaf and we do our little search within that single leaf, we see 20 is there, and we get our answer.
   So this logic here, this is broken forescans, OK? A scan is a just says, you know, let's start from all values that are greater than something and less than something. It's the sub range, we're scanning across a sum of stuff and this is broken for scans, because if we project the pending operations onto each path, then for instance we can see the root's pending operations are going into every single node, right? It's kind of crazy and so we end up with gems of our sorted tree. 
   It's definitely sorted when it goes 14, 20, 30, 10, 15, right? That's definitely sorted order. So it turns out it's slightly nor complex. What we do is project values only in range. So for a fractal tree and a hitchhiker trees what we end up doing is figure out which operations might end up in that leaf, and then project only those operations. It's a little bit more complex implementationwise, but when we're thinking about it this idea of projecting the path of all the pending operations is what allows us to actually get good results, correct results in your fractal tree reads.
   So I've been talking a lot about fractal tree and maybe you're wondering, OK, I thought this talk was about hitchhiker trees, what's the deal, what's going on here? So one of the big differences between a hitchhiker tree and a fractal tree is whether or not it's using path copying. 
   They're actually designed to be making these modifications and mutations in place and when we look at commercial fractal trees, they typically take advantage of this in order to expose different types of concurrency in their operations in a way that is completely incompatible with a functional data structure.
   In comparison, a hitchhiker tree, one of the most fundamental differences is that a hitchhiker tree uses path copying so that a hitchhiker tree is a functional and immutable data structure that is still able to gain these performance advantages of the faster inserts and the better I/O performance. 
   Another difference between the two of them that is not something that we can really have time to go into this talk is that hitchhiker trees are more optimized for storage, which returns bigger amounts of data at higher latency, whereas fractal trees have really been optimized for things like solid state discs and local discs where there's a slightly performance tradeoff in latency and size of block.
   So let's look at something else, though, OK? Let's talk about flush control. This is another thing that's really important with a hitchhiker tree in terms of understanding where you're gaining performance. So I have the example again of the B+ tree/fractal trie/hitchhiker tree and there were 7 operations that we did. And we have this table, as well. 
   And he each row is the I/O cost for each tree. So the total I/O that's what it sounds like, it's the total number of I/O operations that were done. The I/Os per flush, how many did you do, and then lastly the average I/O that's the total divided by 7, because we're averaging it out. It's not necessarily the max I/Os we did a single time. Instead we're saying what was sort of the average when we averaged it out and so for a B+ tree we have to touch every level of the tree until we get all the way down and let's assume we want to persist those to disk, that means we have to write those out every single time.
   Now, for a fractal tree, we only had to do 12I/Os, because those 12 I/Os, so they could be only 1. But in the worst case, remember when we inserted 100 in that last insertion, that actually caused us to have to write 4 nodes. That's an even worse pause than what the B+ tree caused tows do, so the I/Os per flush can be highly variable on a fractal tree.
   So with a hitchhiker tree we can do even better and with the hitchhiker tree what we're doing is we only have to do five I/Os overall and we can make the decision to not flush until we've made a whole bunch of writes. So in this case we only have one flush which cost five I/O, but it only happened once. So the latency on that flush is quite a bit longer, but in addition to exchange for that increased latency the increase is less than 1I/O per flush, that's pretty great. The other thing I want to point out is with a hitchhiker tree and with its API and also a fractal tree you have this tradeoff. You can flush more often or flush less often and save on I/O costs at the expense of not having your data written to a disk somewhere.
   So real branching factors, all right, it turns out in this these examples we've been looking at stuff with -P 3 or 5 or so many children. But that's how many there typically are. A B+ tree typically has a fanout of one to two thousand.
   We can easily fit that many keys into a single node, so the branching factor to a B+ tree is pretty big, so you might think the branching factor for hitchhiker tree would also be pretty big and it isn't strangely. It's actually much less. It's actually 100, 200, could be even less. So why is that? 
   It's because those buffers in the hitchhiker tree those end up being really huge. Because remember the thing that often we care about, and this is a tradeoff that we can make, is we often care about increasing our insertion time. 
   We want to increase our performance when we're doing operations to the tree, when we're doing writes to the tree and then we're OK maybe having a small penalty on reads, and so there's actually a Wikipedia article about this, I believe, where they show some math again, kind of complex or whatever, and they actually end up getting better than log base B of N for operations on fractal trees because the buffers are so big, and there's various ways you can try to tune this, and what have you.
   OK, so you know, maybe you're thinking this is kind of cool, this is interesting, I'd like to try these fractal trees, these hitchhiker trees, I'd like to play with them. Well, it's on GitHub and it's on a database called Datacrypt Project, entirely written in Clojure and it's pluggable. The backend storage is pluggable. The I/O management flare is pluggable. When you want to flush, when you want to compress data, all of that is up to you. The serialization is pluggable. And. 
   Even the sorting algorithm is pluggable, so you can use the default, you know, JVM sort or you can use an ordinal sort or a lexo graphic sort, it's all pluggable and it gives you this framework, this API for interacting with a hitchhiker tree in a very fundamental way so you can insert things into it, you can delete things from it, you can frush it to disk and do a variety of operations. I mentioned that the hitchhiker tree compared to a fractal tree is designed for even more bigger data: So right now today, you can actually use this also in an application, it works with Redis and it's called the outboard API. It looks like a hash map except the data is stored offheap in Redis, it's not the same thing as Redis, because although Redis is an off-heap hash map pretty much, what hitchhiker tree adds no matter how much data you're storing in Redis, you can make modifications and say snap this and store this and that's free. And in addition to making all these snapshots that you can make whenever you want to, at basically zero cost there's an advantage to the program when you want to resort the virtual recline, it can reconnect to Redis and you're off to the races.
   When we're writing functional programs, we're building these functional systems, we don't have to tie the lifetime of our data structures to the lifetime of our run time which means as we're redeploying code, as we're making changes, all of those things it doesn't mean we have to flush out our memory and that means we can do restarts much faster and that's pretty exciting. So I want to give some shoutouts to Andy Chambers and also to Casey Marshal. 
   So you know, I think the big question now is what are we going to build next? I would love to have anyone or everyone as a contributor to the hitchhiker trees on GitHub at the data tree project. I don't think we have any time for Q & A. So thank you.
   [applause]
